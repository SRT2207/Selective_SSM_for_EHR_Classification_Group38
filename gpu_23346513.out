Wed Dec  4 17:39:16 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:3B:00.0 Off |                    0 |
| N/A   57C    P0             51W /  300W |       1MiB /  32768MiB |      0%   E. Process |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_1_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_1_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_1_val.h5
Loaded dataset from ./processed_datasets/physionet2012_1_test.h5
# of trainable parameters: 9662822
Epoch: 1, Train Loss: 0.6377693286963871, Val Loss: 0.6475149393081665
Validation loss decreased (inf --> 0.337550).  Saving model ...
Epoch: 2, Train Loss: 0.6276010170815483, Val Loss: 0.6466037631034851
Validation loss decreased (0.337550 --> 0.328979).  Saving model ...
Epoch: 3, Train Loss: 0.626091530398717, Val Loss: 0.6399067044258118
EarlyStopping counter: 1 out of 10
Epoch: 4, Train Loss: 0.6213444220641303, Val Loss: 0.6550808548927307
EarlyStopping counter: 2 out of 10
Epoch: 5, Train Loss: 0.6228701193181295, Val Loss: 0.6460915803909302
EarlyStopping counter: 3 out of 10
Epoch: 6, Train Loss: 0.6187456869889819, Val Loss: 0.6425894498825073
Validation loss decreased (0.328979 --> 0.326811).  Saving model ...
Epoch: 7, Train Loss: 0.6160485581273124, Val Loss: 0.6551882028579712
Validation loss decreased (0.326811 --> 0.311149).  Saving model ...
Epoch: 8, Train Loss: 0.6153932918631841, Val Loss: 0.6144167184829712
EarlyStopping counter: 1 out of 10
Epoch: 9, Train Loss: 0.6114405367582564, Val Loss: 0.6444523334503174
EarlyStopping counter: 2 out of 10
Epoch: 10, Train Loss: 0.6055460718889085, Val Loss: 0.6298478841781616
Validation loss decreased (0.311149 --> 0.310845).  Saving model ...
Epoch: 11, Train Loss: 0.5970492263635, Val Loss: 0.6072582006454468
Validation loss decreased (0.310845 --> 0.276033).  Saving model ...
Epoch: 12, Train Loss: 0.5744822446316008, Val Loss: 0.6060323119163513
Validation loss decreased (0.276033 --> 0.234598).  Saving model ...
Epoch: 13, Train Loss: 0.5333555697921722, Val Loss: 0.5558512210845947
Validation loss decreased (0.234598 --> 0.205116).  Saving model ...
Epoch: 14, Train Loss: 0.49348911524765077, Val Loss: 0.5548945069313049
Validation loss decreased (0.205116 --> 0.196268).  Saving model ...
Epoch: 15, Train Loss: 0.45338498517161324, Val Loss: 0.4869234561920166
Validation loss decreased (0.196268 --> 0.180369).  Saving model ...
Epoch: 16, Train Loss: 0.4092026445127669, Val Loss: 0.5164099335670471
EarlyStopping counter: 1 out of 10
Epoch: 17, Train Loss: 0.36146800834981224, Val Loss: 0.5132978558540344
EarlyStopping counter: 2 out of 10
Epoch: 18, Train Loss: 0.30671150970553596, Val Loss: 0.5235673189163208
EarlyStopping counter: 3 out of 10
Epoch: 19, Train Loss: 0.24895728072003712, Val Loss: 0.5670500993728638
EarlyStopping counter: 4 out of 10
Epoch: 20, Train Loss: 0.19034166622256476, Val Loss: 0.6566230654716492
EarlyStopping counter: 5 out of 10
Epoch: 21, Train Loss: 0.15221862577729756, Val Loss: 0.7108438611030579
EarlyStopping counter: 6 out of 10
Epoch: 22, Train Loss: 0.13738633506000042, Val Loss: 0.7151641845703125
EarlyStopping counter: 7 out of 10
Epoch: 23, Train Loss: 0.10405340696138049, Val Loss: 0.8042974472045898
EarlyStopping counter: 8 out of 10
Epoch: 24, Train Loss: 0.09094577063141125, Val Loss: 0.8691241145133972
EarlyStopping counter: 9 out of 10
Epoch: 25, Train Loss: 0.083952456897509, Val Loss: 0.8180932402610779
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.46602490544319153
{'0': {'precision': 0.9404761904761905, 'recall': 0.7684824902723736, 'f1-score': 0.8458244111349036, 'support': 1028.0}, '1': {'precision': 0.3370473537604457, 'recall': 0.7076023391812866, 'f1-score': 0.45660377358490567, 'support': 171.0}, 'accuracy': 0.7597998331943286, 'macro avg': {'precision': 0.6387617721183181, 'recall': 0.7380424147268301, 'f1-score': 0.6512140923599046, 'support': 1199.0}, 'weighted avg': {'precision': 0.8544158643057215, 'recall': 0.7597998331943286, 'f1-score': 0.7903142117845703, 'support': 1199.0}}
[[790 238]
 [ 50 121]]
Accuracy = 0.7597998331943286
AUPRC = 0.4528113379651623
AUROC = 0.8357339522606776
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_2_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_2_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_2_val.h5
Loaded dataset from ./processed_datasets/physionet2012_2_test.h5
# of trainable parameters: 9662822
Epoch: 1, Train Loss: 0.6394863417372108, Val Loss: 0.597321629524231
Validation loss decreased (inf --> 0.305942).  Saving model ...
Epoch: 2, Train Loss: 0.6265111505053937, Val Loss: 0.6289458274841309
Validation loss decreased (0.305942 --> 0.304477).  Saving model ...
Epoch: 3, Train Loss: 0.6223968400154263, Val Loss: 0.6006892919540405
Validation loss decreased (0.304477 --> 0.296076).  Saving model ...
Epoch: 4, Train Loss: 0.6177113354206085, Val Loss: 0.5988510847091675
Validation loss decreased (0.296076 --> 0.284522).  Saving model ...
Epoch: 5, Train Loss: 0.6148449769243598, Val Loss: 0.5976853966712952
Validation loss decreased (0.284522 --> 0.274390).  Saving model ...
Epoch: 6, Train Loss: 0.6111346187535673, Val Loss: 0.6056819558143616
EarlyStopping counter: 1 out of 10
Epoch: 7, Train Loss: 0.6092252251692116, Val Loss: 0.5932528972625732
Validation loss decreased (0.274390 --> 0.262793).  Saving model ...
Epoch: 8, Train Loss: 0.6011263383552432, Val Loss: 0.6263022422790527
Validation loss decreased (0.262793 --> 0.255735).  Saving model ...
Epoch: 9, Train Loss: 0.5842839409597218, Val Loss: 0.6108392477035522
Validation loss decreased (0.255735 --> 0.218249).  Saving model ...
Epoch: 10, Train Loss: 0.5334763831924647, Val Loss: 0.5457291007041931
Validation loss decreased (0.218249 --> 0.187684).  Saving model ...
Epoch: 11, Train Loss: 0.4948089241515845, Val Loss: 0.5592976808547974
Validation loss decreased (0.187684 --> 0.171316).  Saving model ...
Epoch: 12, Train Loss: 0.46283889655023813, Val Loss: 0.5420061349868774
Validation loss decreased (0.171316 --> 0.160638).  Saving model ...
Epoch: 13, Train Loss: 0.4327339029405266, Val Loss: 0.510362982749939
Validation loss decreased (0.160638 --> 0.158769).  Saving model ...
Epoch: 14, Train Loss: 0.4045990811428055, Val Loss: 0.48088371753692627
EarlyStopping counter: 1 out of 10
Epoch: 15, Train Loss: 0.3715619081631303, Val Loss: 0.4634484350681305
EarlyStopping counter: 2 out of 10
Epoch: 16, Train Loss: 0.31356884620618075, Val Loss: 0.507359504699707
EarlyStopping counter: 3 out of 10
Epoch: 17, Train Loss: 0.26022742077475414, Val Loss: 0.4961724877357483
EarlyStopping counter: 4 out of 10
Epoch: 18, Train Loss: 0.20315390772884712, Val Loss: 0.517021656036377
EarlyStopping counter: 5 out of 10
Epoch: 19, Train Loss: 0.1569290541810915, Val Loss: 0.6706321239471436
EarlyStopping counter: 6 out of 10
Epoch: 20, Train Loss: 0.1240802431711927, Val Loss: 0.5851255655288696
EarlyStopping counter: 7 out of 10
Epoch: 21, Train Loss: 0.10999698626983445, Val Loss: 0.6222383379936218
EarlyStopping counter: 8 out of 10
Epoch: 22, Train Loss: 0.07838327075296547, Val Loss: 0.7333793640136719
EarlyStopping counter: 9 out of 10
Epoch: 23, Train Loss: 0.07826233784726355, Val Loss: 0.6322801113128662
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.5054197907447815
{'0': {'precision': 0.9508599508599509, 'recall': 0.7442307692307693, 'f1-score': 0.8349514563106796, 'support': 1040.0}, '1': {'precision': 0.3090909090909091, 'recall': 0.7484276729559748, 'f1-score': 0.4375, 'support': 159.0}, 'accuracy': 0.7447873227689742, 'macro avg': {'precision': 0.62997542997543, 'recall': 0.7463292210933721, 'f1-score': 0.6362257281553398, 'support': 1199.0}, 'weighted avg': {'precision': 0.8657546317262749, 'recall': 0.7447873227689742, 'f1-score': 0.7822452164829914, 'support': 1199.0}}
[[774 266]
 [ 40 119]]
Accuracy = 0.7447873227689742
AUPRC = 0.45212007726434794
AUROC = 0.8186441702951137
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_3_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_3_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_3_val.h5
Loaded dataset from ./processed_datasets/physionet2012_3_test.h5
# of trainable parameters: 9662822
Epoch: 1, Train Loss: 0.6458084512883284, Val Loss: 0.6353325843811035
Validation loss decreased (inf --> 0.318656).  Saving model ...
Epoch: 2, Train Loss: 0.6277484785853409, Val Loss: 0.6497917175292969
Validation loss decreased (0.318656 --> 0.317567).  Saving model ...
Epoch: 3, Train Loss: 0.624967081809607, Val Loss: 0.6452059149742126
EarlyStopping counter: 1 out of 10
Epoch: 4, Train Loss: 0.6214403812810192, Val Loss: 0.6312777996063232
Validation loss decreased (0.317567 --> 0.309153).  Saving model ...
Epoch: 5, Train Loss: 0.6204680617400041, Val Loss: 0.6529678106307983
Validation loss decreased (0.309153 --> 0.301022).  Saving model ...
Epoch: 6, Train Loss: 0.6163611473060968, Val Loss: 0.6524394750595093
Validation loss decreased (0.301022 --> 0.288141).  Saving model ...
Epoch: 7, Train Loss: 0.6169665779654435, Val Loss: 0.6442884802818298
EarlyStopping counter: 1 out of 10
Epoch: 8, Train Loss: 0.6101559057949096, Val Loss: 0.6349969506263733
EarlyStopping counter: 2 out of 10
Epoch: 9, Train Loss: 0.6092887084315143, Val Loss: 0.6205055713653564
EarlyStopping counter: 3 out of 10
Epoch: 10, Train Loss: 0.608057216396482, Val Loss: 0.6451616287231445
EarlyStopping counter: 4 out of 10
Epoch: 11, Train Loss: 0.6027581405451917, Val Loss: 0.6419451236724854
Validation loss decreased (0.288141 --> 0.273182).  Saving model ...
Epoch: 12, Train Loss: 0.5943657906036678, Val Loss: 0.6424791216850281
Validation loss decreased (0.273182 --> 0.254796).  Saving model ...
Epoch: 13, Train Loss: 0.5822597054515298, Val Loss: 0.6286390423774719
Validation loss decreased (0.254796 --> 0.227448).  Saving model ...
Epoch: 14, Train Loss: 0.5454907724707145, Val Loss: 0.5133187174797058
Validation loss decreased (0.227448 --> 0.207530).  Saving model ...
Epoch: 15, Train Loss: 0.5089993397081931, Val Loss: 0.6134558320045471
Validation loss decreased (0.207530 --> 0.191842).  Saving model ...
Epoch: 16, Train Loss: 0.4813955782905338, Val Loss: 0.514339804649353
Validation loss decreased (0.191842 --> 0.181504).  Saving model ...
Epoch: 17, Train Loss: 0.4598467009743368, Val Loss: 0.5255771279335022
Validation loss decreased (0.181504 --> 0.169204).  Saving model ...
Epoch: 18, Train Loss: 0.42888769742072097, Val Loss: 0.564772367477417
EarlyStopping counter: 1 out of 10
Epoch: 19, Train Loss: 0.40792302036379263, Val Loss: 0.48162171244621277
EarlyStopping counter: 2 out of 10
Epoch: 20, Train Loss: 0.3737169203795786, Val Loss: 0.5166153311729431
EarlyStopping counter: 3 out of 10
Epoch: 21, Train Loss: 0.3480309955482408, Val Loss: 0.5297459363937378
EarlyStopping counter: 4 out of 10
Epoch: 22, Train Loss: 0.3211936322957512, Val Loss: 0.528290331363678
EarlyStopping counter: 5 out of 10
Epoch: 23, Train Loss: 0.2869941637975963, Val Loss: 0.5334373116493225
EarlyStopping counter: 6 out of 10
Epoch: 24, Train Loss: 0.26540724487285916, Val Loss: 0.5598428845405579
EarlyStopping counter: 7 out of 10
Epoch: 25, Train Loss: 0.23836579907128191, Val Loss: 0.5177883505821228
EarlyStopping counter: 8 out of 10
Epoch: 26, Train Loss: 0.22231987629115113, Val Loss: 0.5776141881942749
EarlyStopping counter: 9 out of 10
Epoch: 27, Train Loss: 0.19894122437933298, Val Loss: 0.580185055732727
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.5448709726333618
{'0': {'precision': 0.9479843953185956, 'recall': 0.713307240704501, 'f1-score': 0.8140703517587939, 'support': 1022.0}, '1': {'precision': 0.3186046511627907, 'recall': 0.7740112994350282, 'f1-score': 0.4514003294892916, 'support': 177.0}, 'accuracy': 0.7222685571309424, 'macro avg': {'precision': 0.6332945232406931, 'recall': 0.7436592700697646, 'f1-score': 0.6327353406240428, 'support': 1199.0}, 'weighted avg': {'precision': 0.8550734572739104, 'recall': 0.7222685571309424, 'f1-score': 0.7605319081043304, 'support': 1199.0}}
[[729 293]
 [ 40 137]]
Accuracy = 0.7222685571309424
AUPRC = 0.3973429373889121
AUROC = 0.7954161000364854
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_4_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_4_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_4_val.h5
Loaded dataset from ./processed_datasets/physionet2012_4_test.h5
# of trainable parameters: 9662822
Epoch: 1, Train Loss: 0.6341760531067848, Val Loss: 0.6515780091285706
Validation loss decreased (inf --> 0.367962).  Saving model ...
Epoch: 2, Train Loss: 0.6198230283334851, Val Loss: 0.6412139534950256
Validation loss decreased (0.367962 --> 0.357523).  Saving model ...
Epoch: 3, Train Loss: 0.6171619757078588, Val Loss: 0.6779088377952576
Validation loss decreased (0.357523 --> 0.357059).  Saving model ...
Epoch: 4, Train Loss: 0.6113376040011644, Val Loss: 0.6437422037124634
Validation loss decreased (0.357059 --> 0.352702).  Saving model ...
Epoch: 5, Train Loss: 0.6110815349966288, Val Loss: 0.6537006497383118
EarlyStopping counter: 1 out of 10
Epoch: 6, Train Loss: 0.6069183361250907, Val Loss: 0.6701593995094299
EarlyStopping counter: 2 out of 10
Epoch: 7, Train Loss: 0.6058254714589566, Val Loss: 0.6636741161346436
EarlyStopping counter: 3 out of 10
Epoch: 8, Train Loss: 0.603048084769398, Val Loss: 0.6728206276893616
EarlyStopping counter: 4 out of 10
Epoch: 9, Train Loss: 0.6001002970151603, Val Loss: 0.6586376428604126
EarlyStopping counter: 5 out of 10
Epoch: 10, Train Loss: 0.589704841375351, Val Loss: 0.64683997631073
Validation loss decreased (0.352702 --> 0.349522).  Saving model ...
Epoch: 11, Train Loss: 0.5804533404298127, Val Loss: 0.644759476184845
Validation loss decreased (0.349522 --> 0.318769).  Saving model ...
Epoch: 12, Train Loss: 0.5553181928116828, Val Loss: 0.5993705987930298
Validation loss decreased (0.318769 --> 0.280839).  Saving model ...
Epoch: 13, Train Loss: 0.5065583984833211, Val Loss: 0.5971212983131409
Validation loss decreased (0.280839 --> 0.254503).  Saving model ...
Epoch: 14, Train Loss: 0.4725746053736657, Val Loss: 0.5475255846977234
Validation loss decreased (0.254503 --> 0.231154).  Saving model ...
Epoch: 15, Train Loss: 0.42407651722896844, Val Loss: 0.5259435772895813
Validation loss decreased (0.231154 --> 0.219700).  Saving model ...
Epoch: 16, Train Loss: 0.35702377068810165, Val Loss: 0.5416378378868103
EarlyStopping counter: 1 out of 10
Epoch: 17, Train Loss: 0.26839342853054404, Val Loss: 0.5614978075027466
Validation loss decreased (0.219700 --> 0.219607).  Saving model ...
Epoch: 18, Train Loss: 0.19004864152520895, Val Loss: 0.590387225151062
Validation loss decreased (0.219607 --> 0.212732).  Saving model ...
Epoch: 19, Train Loss: 0.1362114242365351, Val Loss: 0.6277945041656494
Validation loss decreased (0.212732 --> 0.210619).  Saving model ...
Epoch: 20, Train Loss: 0.09425571101746755, Val Loss: 0.6978391408920288
EarlyStopping counter: 1 out of 10
Epoch: 21, Train Loss: 0.09144800136709819, Val Loss: 0.6094562411308289
EarlyStopping counter: 2 out of 10
Epoch: 22, Train Loss: 0.07145756488171173, Val Loss: 0.6602715849876404
EarlyStopping counter: 3 out of 10
Epoch: 23, Train Loss: 0.06356306407906231, Val Loss: 0.7282106280326843
Validation loss decreased (0.210619 --> 0.208188).  Saving model ...
Epoch: 24, Train Loss: 0.05179233029775787, Val Loss: 0.6974684000015259
EarlyStopping counter: 1 out of 10
Epoch: 25, Train Loss: 0.04847147811597097, Val Loss: 0.8785069584846497
EarlyStopping counter: 2 out of 10
Epoch: 26, Train Loss: 0.04523752150271321, Val Loss: 0.775259792804718
EarlyStopping counter: 3 out of 10
Epoch: 27, Train Loss: 0.053517829430347774, Val Loss: 0.7792669534683228
EarlyStopping counter: 4 out of 10
Epoch: 28, Train Loss: 0.03159150164719904, Val Loss: 0.8177269101142883
EarlyStopping counter: 5 out of 10
Epoch: 29, Train Loss: 0.02792748744286655, Val Loss: 0.8514420986175537
EarlyStopping counter: 6 out of 10
Epoch: 30, Train Loss: 0.02564546670510026, Val Loss: 0.9915180802345276
EarlyStopping counter: 7 out of 10
Epoch: 31, Train Loss: 0.03444678625510278, Val Loss: 0.8582739233970642
EarlyStopping counter: 8 out of 10
Epoch: 32, Train Loss: 0.04477952454362821, Val Loss: 0.8018755912780762
EarlyStopping counter: 9 out of 10
Epoch: 33, Train Loss: 0.028171665009722346, Val Loss: 0.9373793601989746
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.7169405221939087
{'0': {'precision': 0.9065989847715736, 'recall': 0.8754901960784314, 'f1-score': 0.8907730673316708, 'support': 1020.0}, '1': {'precision': 0.40654205607476634, 'recall': 0.4860335195530726, 'f1-score': 0.44274809160305345, 'support': 179.0}, 'accuracy': 0.817347789824854, 'macro avg': {'precision': 0.65657052042317, 'recall': 0.6807618578157519, 'f1-score': 0.6667605794673621, 'support': 1199.0}, 'weighted avg': {'precision': 0.8319449478768877, 'recall': 0.817347789824854, 'f1-score': 0.8238869366766062, 'support': 1199.0}}
[[893 127]
 [ 92  87]]
Accuracy = 0.817347789824854
AUPRC = 0.39452583305123035
AUROC = 0.7784751889582648
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_5_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_5_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_5_val.h5
Loaded dataset from ./processed_datasets/physionet2012_5_test.h5
# of trainable parameters: 9662822
Epoch: 1, Train Loss: 0.6439381246348373, Val Loss: 0.6315585970878601
Validation loss decreased (inf --> 0.315325).  Saving model ...
Epoch: 2, Train Loss: 0.6333607794674299, Val Loss: 0.6125573515892029
Validation loss decreased (0.315325 --> 0.310195).  Saving model ...
Epoch: 3, Train Loss: 0.6255012928074553, Val Loss: 0.6284613013267517
Validation loss decreased (0.310195 --> 0.302553).  Saving model ...
Epoch: 4, Train Loss: 0.6252952577503583, Val Loss: 0.614961564540863
Validation loss decreased (0.302553 --> 0.300147).  Saving model ...
Epoch: 5, Train Loss: 0.6219023297761233, Val Loss: 0.6171061992645264
Validation loss decreased (0.300147 --> 0.289494).  Saving model ...
Epoch: 6, Train Loss: 0.6203212883636242, Val Loss: 0.6146211624145508
EarlyStopping counter: 1 out of 10
Epoch: 7, Train Loss: 0.6179974329380589, Val Loss: 0.6229852437973022
EarlyStopping counter: 2 out of 10
Epoch: 8, Train Loss: 0.6199122189565469, Val Loss: 0.6136206984519958
Validation loss decreased (0.289494 --> 0.283170).  Saving model ...
Epoch: 9, Train Loss: 0.6147002664231161, Val Loss: 0.6111283898353577
EarlyStopping counter: 1 out of 10
Epoch: 10, Train Loss: 0.6160786461284142, Val Loss: 0.6176623106002808
Validation loss decreased (0.283170 --> 0.281971).  Saving model ...
Epoch: 11, Train Loss: 0.6137982802536651, Val Loss: 0.6072280406951904
Validation loss decreased (0.281971 --> 0.281458).  Saving model ...
Epoch: 12, Train Loss: 0.609187426685377, Val Loss: 0.6151241064071655
Validation loss decreased (0.281458 --> 0.268318).  Saving model ...
Epoch: 13, Train Loss: 0.6014112325115059, Val Loss: 0.6403980851173401
Validation loss decreased (0.268318 --> 0.263944).  Saving model ...
Epoch: 14, Train Loss: 0.6012711766111942, Val Loss: 0.6207363605499268
Validation loss decreased (0.263944 --> 0.262772).  Saving model ...
Epoch: 15, Train Loss: 0.5911757541066818, Val Loss: 0.6057978868484497
Validation loss decreased (0.262772 --> 0.249266).  Saving model ...
Epoch: 16, Train Loss: 0.5772977216553142, Val Loss: 0.6030851006507874
Validation loss decreased (0.249266 --> 0.244561).  Saving model ...
Epoch: 17, Train Loss: 0.5627547420618189, Val Loss: 0.5677453279495239
Validation loss decreased (0.244561 --> 0.222941).  Saving model ...
Epoch: 18, Train Loss: 0.53809007865782, Val Loss: 0.5352976322174072
Validation loss decreased (0.222941 --> 0.209113).  Saving model ...
Epoch: 19, Train Loss: 0.512967558989998, Val Loss: 0.5344022512435913
Validation loss decreased (0.209113 --> 0.208144).  Saving model ...
Epoch: 20, Train Loss: 0.4774982547032014, Val Loss: 0.5367432832717896
Validation loss decreased (0.208144 --> 0.196528).  Saving model ...
Epoch: 21, Train Loss: 0.4528555312684474, Val Loss: 0.5502788424491882
EarlyStopping counter: 1 out of 10
Epoch: 22, Train Loss: 0.4126451368095311, Val Loss: 0.5710097551345825
Validation loss decreased (0.196528 --> 0.194723).  Saving model ...
Epoch: 23, Train Loss: 0.370181038748217, Val Loss: 0.535681426525116
EarlyStopping counter: 1 out of 10
Epoch: 24, Train Loss: 0.3318301551897107, Val Loss: 0.5120831727981567
EarlyStopping counter: 2 out of 10
Epoch: 25, Train Loss: 0.2909753815135883, Val Loss: 0.5540481209754944
EarlyStopping counter: 3 out of 10
Epoch: 26, Train Loss: 0.25336251385111846, Val Loss: 0.6140137314796448
EarlyStopping counter: 4 out of 10
Epoch: 27, Train Loss: 0.22526539492470618, Val Loss: 0.5964966416358948
EarlyStopping counter: 5 out of 10
Epoch: 28, Train Loss: 0.22131422662552985, Val Loss: 0.6238887906074524
EarlyStopping counter: 6 out of 10
Epoch: 29, Train Loss: 0.18726247375589292, Val Loss: 0.5745972990989685
EarlyStopping counter: 7 out of 10
Epoch: 30, Train Loss: 0.16162430910208753, Val Loss: 0.6180132031440735
EarlyStopping counter: 8 out of 10
Epoch: 31, Train Loss: 0.1442131000421657, Val Loss: 0.5909395217895508
EarlyStopping counter: 9 out of 10
Epoch: 32, Train Loss: 0.1345028295146145, Val Loss: 0.6321848630905151
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.5558980107307434
{'0': {'precision': 0.9482976040353089, 'recall': 0.7279767666989352, 'f1-score': 0.823658269441402, 'support': 1033.0}, '1': {'precision': 0.3078817733990148, 'recall': 0.7530120481927711, 'f1-score': 0.4370629370629371, 'support': 166.0}, 'accuracy': 0.731442869057548, 'macro avg': {'precision': 0.6280896887171619, 'recall': 0.7404944074458532, 'f1-score': 0.6303606032521696, 'support': 1199.0}, 'weighted avg': {'precision': 0.8596328601774067, 'recall': 0.731442869057548, 'f1-score': 0.7701346454423819, 'support': 1199.0}}
[[752 281]
 [ 41 125]]
Accuracy = 0.731442869057548
AUPRC = 0.3908928306058484
AUROC = 0.8022253583550076
